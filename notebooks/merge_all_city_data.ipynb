{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Landprices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import osmnx as ox "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector data \n",
    "We start by reading and quickly visualising vector data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read raster data\n",
    "\n",
    "We read the census data that is classified in a grid, then we read the grid as a geopandas file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZENSUS_PATH = r\"../data/raw/2 Zensus/\"\n",
    "NEIGHBORHOOD_PATH =  r\"../data/raw/3 Neighborhoods\"\n",
    "LAND_PRICES_PATH = r\"../data/raw/1 Land Prices\"\n",
    "CITY_NAMES=[\"Berlin\",\"Bremen\",\"Dresden\",\"Frankfurt\",\"Köln\"]\n",
    "zensus_files= os.listdir(ZENSUS_PATH)\n",
    "neighborhood_files= os.listdir(NEIGHBORHOOD_PATH)\n",
    "landprices_files= os.listdir(LAND_PRICES_PATH)\n",
    "\n",
    "def get_file_names(): \n",
    "    city_files={}\n",
    "    for city_name in CITY_NAMES:\n",
    "        \n",
    "        csv_fpaths= [os.path.join(ZENSUS_PATH,fpath) for fpath in zensus_files if ( city_name in fpath ) and (fpath.endswith(\".csv\")) ]\n",
    "        gpkg_fpaths= [os.path.join(ZENSUS_PATH,fpath) for fpath in zensus_files if ( city_name in fpath ) and (fpath.endswith(\".gpkg\")) ]\n",
    "        \n",
    "        neighbourhood_fpaths= [os.path.join(NEIGHBORHOOD_PATH,fpath) for fpath in neighborhood_files if ( city_name in fpath ) and (fpath.endswith(\".gpkg\")) ]\n",
    "        landprices_fpaths= [os.path.join(LAND_PRICES_PATH,fpath) for fpath in landprices_files if ( city_name in fpath ) ]\n",
    "\n",
    "        city_files[city_name]= (csv_fpaths,gpkg_fpaths,neighbourhood_fpaths,landprices_fpaths)\n",
    "    return city_files\n",
    "\n",
    "def combine_data_within_city(city_files):\n",
    "    city_merged_data={}\n",
    "    for city_name, (csv_fpaths,gpkg_fpaths,neighbourhood_fpaths,landprices_fpaths) in city_files.items():\n",
    "        df_list_city=[]\n",
    "        for csv_fpath in csv_fpaths:\n",
    "            df = pd.read_csv(csv_fpath, sep=\";\", encoding=\"utf-8-sig\").drop(columns=\"Unnamed: 0\")\n",
    "            df_list_city.append(df)\n",
    "\n",
    "        from functools import reduce\n",
    "        zensus_csv_merged = reduce(lambda df1,df2: pd.merge(df1,df2,on=\"Grid_Code\"), df_list_city)\n",
    "        \n",
    "        # read grid\n",
    "        grid_city = gpd.read_file(gpkg_fpaths[0])\n",
    "        grid_city = grid_city.merge(zensus_csv_merged, on = \"Grid_Code\")\n",
    "\n",
    "        # merge files\n",
    "        prices_city = pd.read_csv(landprices_fpaths[0], sep=\";\", encoding= \"utf-8-sig\").drop(columns=\"Unnamed: 0\")\n",
    "        neighborhood_city = gpd.read_file(neighbourhood_fpaths[0])\n",
    "        neighborhood_city = neighborhood_city.merge(prices_city, on = \"Neighborhood_FID\", how = \"inner\")\n",
    "\n",
    "        neighborhood_city_4326 = neighborhood_city.to_crs(epsg = 4326)\n",
    "        amenity_features = get_amenity_features(neighborhood_city_4326)\n",
    "\n",
    "        # Perform spatial join using sjoin\n",
    "        merged_data = gpd.sjoin(grid_city, neighborhood_city, how='left', op='intersects')\n",
    "        merged_data = merged_data.drop(columns=[\"City_Name_y\", \"City_Code_right\"]).rename(columns={\"City_Name_x\":\"City_Name\", \"City_Code_left\":\"City_Code\"})\n",
    "        city_merged_data[city_name] = merged_data\n",
    "    return city_merged_data\n",
    "\n",
    "def concat_city_dataframes(city_merged_data):\n",
    "    col_list=[]\n",
    "    for city_name,df in city_merged_data.items():\n",
    "        print(df.shape)\n",
    "        col_list.append(df.columns.to_list())\n",
    "    common_cols=list(set(col_list[0]).intersection(*col_list))\n",
    "\n",
    "    grid_level_df_list = [df[common_cols] for df in city_merged_data.values()]\n",
    "    grid_level_all_cities = pd.concat(grid_level_df_list, axis=0)\n",
    "    return grid_level_all_cities\n",
    "\n",
    "def get_amenity_features(neighborhoods):\n",
    "    # Define the tag to extract (amenity=restaurant)\n",
    "    tag = {'amenity':True}\n",
    "\n",
    "    # Define an empty list to store the results\n",
    "    results = {}\n",
    "\n",
    "    # Loop over each neighborhood and extract the restaurants\n",
    "    for i, nb_name in enumerate(neighborhoods.Neighborhood_Name):\n",
    "        nb = neighborhoods.loc[neighborhoods.Neighborhood_Name == nb_name]\n",
    "        restaurants = ox.geometries.geometries_from_polygon(polygon=nb.geometry.iloc[0], tags=tag)\n",
    "        # print(f'Processed {i+1}/{len(neighborhoods)} neighborhoods ({nb_name}): found {restaurants.shape[0]} restaurants')\n",
    "        results[nb_name] = restaurants\n",
    "\n",
    "    nb_results = []\n",
    "\n",
    "    for i, nb_name in enumerate(neighborhoods.Neighborhood_Name):\n",
    "        nb_result = pd.DataFrame(results[nb_name].amenity.value_counts().to_dict(), index=[i])\n",
    "        nb_result[\"Neighborhood_Name\"]=nb_name\n",
    "        #nb_result[\"City_Name\"]=neighborhoods.City_Name\n",
    "        nb_results.append(nb_result)\n",
    "\n",
    "    # Combine the results into a single GeoDataFrame\n",
    "    combined_results = pd.concat(nb_results, ignore_index=True)\n",
    "    \n",
    "\n",
    "    DROPNA_TRESH=0.8\n",
    "    combined_results = combined_results.loc[:, combined_results.isnull().mean() < DROPNA_TRESH]\n",
    "\n",
    "    return combined_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\ifohack_spatial_py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3505: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "c:\\anaconda3\\envs\\ifohack_spatial_py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3505: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "c:\\anaconda3\\envs\\ifohack_spatial_py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3505: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "c:\\anaconda3\\envs\\ifohack_spatial_py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3505: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "c:\\anaconda3\\envs\\ifohack_spatial_py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3505: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96838, 194)\n",
      "(35637, 196)\n",
      "(37357, 194)\n",
      "(27329, 193)\n",
      "(45330, 194)\n"
     ]
    }
   ],
   "source": [
    "city_files= get_file_names()\n",
    "\n",
    "\n",
    "city_merged_data = combine_data_within_city(city_files)\n",
    "\n",
    "grid_level_all_cities= concat_city_dataframes(city_merged_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neighborhood_FID_lookup = grid_level_all_cities.filter(regex=\"Neighborhood|City\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 50FA-7BE6\n",
      "\n",
      " Directory of c:\\Users\\BerkÖztürk\\ifohack-landers-group\\notebooks\n",
      "\n",
      "30/04/2023  11:01    <DIR>          .\n",
      "30/04/2023  10:59    <DIR>          ..\n",
      "28/04/2023  20:27                 0 .gitkeep\n",
      "29/04/2023  21:51            33.150 baseline.ipynb\n",
      "30/04/2023  09:10             5.583 bokeh_vis.ipynb\n",
      "30/04/2023  09:59    <DIR>          cache\n",
      "30/04/2023  09:10            29.117 connectedness_neighbourhoods.ipynb\n",
      "29/04/2023  12:13             7.236 data analysis.ipynb\n",
      "28/04/2023  21:31    <DIR>          data_example\n",
      "30/04/2023  09:46            10.080 merge_all_city_data.ipynb\n",
      "30/04/2023  09:10        16.171.008 merged_data.gpkg\n",
      "29/04/2023  14:52    <DIR>          mlruns\n",
      "29/04/2023  18:03            50.910 oms_features.ipynb\n",
      "30/04/2023  09:10    <DIR>          quickstart_notebooks\n",
      "30/04/2023  09:10            18.360 segregation.ipynb\n",
      "30/04/2023  09:10             4.278 streamlit.py\n",
      "              10 File(s)     16.329.722 bytes\n",
      "               6 Dir(s)  265.963.282.432 bytes free\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x2341528fd00>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\anaconda3\\envs\\ifohack_spatial_py310\\lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedWriter name=3>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\anaconda3\\envs\\ifohack_spatial_py310\\lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedReader name=4>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\anaconda3\\envs\\ifohack_spatial_py310\\lib\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedReader name=5>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neighborhood_FID_lookup.to_csv(\"../data/interim/Neighborhood_FID_lookup.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_area_names=pd.Series(grid_level_all_cities.Area_Types.unique()).str.split(\"_\")\n",
    "unique_area_cols = pd.Series(np.concatenate(splitted_area_names)).unique().tolist()\n",
    "for unique_area_col in unique_area_cols:\n",
    "    grid_level_all_cities['is_{}'.format(unique_area_col)]= grid_level_all_cities.Area_Types.str.contains(unique_area_col).astype(int)\n",
    "grid_level_all_cities = grid_level_all_cities.drop(columns='Area_Types')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "numeric_cols = grid_level_all_cities.select_dtypes(include=['int32','int64']).columns\n",
    "non_numeric_cols = grid_level_all_cities.select_dtypes(exclude=['int32','int64']).columns\n",
    "\n",
    "agg_operations= dict(zip(numeric_cols, ['mean']*len(numeric_cols) ))\n",
    "agg_operations[\"Land_Value\"]=\"first\"\n",
    "grid_level_all_cities_neighborhood_level =  grid_level_all_cities.groupby(['City_Name','Neighborhood_Name']).agg(agg_operations).reset_index()\n",
    "#grid_level_all_cities_neighborhood_level= grid_level_all_cities_neighborhood_level.drop(columns='index_right')#.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_level_all_cities_neighborhood_level.to_csv('../data/interim/nb_level_merged_all_cities.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged data to file\n",
    "grid_level_all_cities.to_file('../data/interim/grid_level_merged_all_cities.gpkg', driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421, 186)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_level_all_cities_neighborhood_level.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenity_data={}\n",
    "for city_name, (csv_fpaths,gpkg_fpaths,neighbourhood_fpaths,landprices_fpaths) in city_files.items():\n",
    "    neighborhood_city = gpd.read_file(neighbourhood_fpaths[0])\n",
    "    neighborhood_city_4326 = neighborhood_city.to_crs(epsg = 4326)\n",
    "    amenity_features = get_amenity_features(neighborhood_city_4326)\n",
    "    amenity_data[city_name] = amenity_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenity_data_all_cities = pd.concat(amenity_data.values(), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhood_Name</th>\n",
       "      <th>City_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mitte</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Moabit</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hansaviertel</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tiergarten</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wedding</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Fühlingen</td>\n",
       "      <td>Köln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Blumenberg</td>\n",
       "      <td>Köln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Libur</td>\n",
       "      <td>Köln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Poll</td>\n",
       "      <td>Köln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Humboldt/Gremberg</td>\n",
       "      <td>Köln</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>443 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Neighborhood_Name City_Name\n",
       "0               Mitte    Berlin\n",
       "1              Moabit    Berlin\n",
       "2        Hansaviertel    Berlin\n",
       "3          Tiergarten    Berlin\n",
       "4             Wedding    Berlin\n",
       "..                ...       ...\n",
       "81          Fühlingen      Köln\n",
       "82         Blumenberg      Köln\n",
       "83              Libur      Köln\n",
       "84               Poll      Köln\n",
       "85  Humboldt/Gremberg      Köln\n",
       "\n",
       "[443 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amenity_data_all_cities.filter(regex=\"Neig|City|AGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.merge(grid_level_all_cities_neighborhood_level,amenity_data_all_cities,how=\"inner\",on=[\"Neighborhood_Name\",\"City_Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv('../data/interim/nb_level_merged_all_cities_with_amenties.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ifohack_spatial_py310_small_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
